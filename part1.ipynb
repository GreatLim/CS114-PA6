{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create distributional semantic word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the co-occurrence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bite', 'dogs', 'feed', 'like', 'men', 'the', 'women'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"dist_sim_data.txt\")\n",
    "word_set = set()\n",
    "lines = f.readlines()\n",
    "for line in lines:\n",
    "    for word in line[:-1].split(\" \"):\n",
    "        word_set.add(word)\n",
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'dogs', 1: 'men', 2: 'feed', 3: 'women', 4: 'the', 5: 'bite', 6: 'like'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "word_to_index = {}\n",
    "index = 0\n",
    "for word in word_set:\n",
    "    index_to_word[index] = word\n",
    "    word_to_index[word] = index\n",
    "    index += 1\n",
    "index_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(word_set)\n",
    "count = np.zeros(size)\n",
    "co_count = np.zeros((size, size))\n",
    "for line in lines:\n",
    "    pre_word = \"\"\n",
    "    for i, word in enumerate(line[:-1].split(\" \")):\n",
    "        count[word_to_index[word]] += 1\n",
    "        if i != 0:\n",
    "            pre_word_index = word_to_index[pre_word]\n",
    "            word_index = word_to_index[word]\n",
    "            co_count[pre_word_index, word_index] += 1\n",
    "            co_count[word_index, pre_word_index] += 1\n",
    "        pre_word = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.,  8.,  4.,  5., 22.,  3.,  4.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 9., 3., 1.],\n",
       "       [0., 0., 2., 0., 8., 0., 2.],\n",
       "       [0., 2., 0., 2., 4., 0., 0.],\n",
       "       [0., 0., 2., 0., 5., 0., 1.],\n",
       "       [9., 8., 4., 5., 0., 3., 4.],\n",
       "       [3., 0., 0., 0., 3., 0., 0.],\n",
       "       [1., 2., 0., 1., 4., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Multiply your entire matrix by 10 (to pretend that we see these sentences 10 times) and then smooth the counts by adding 1 to all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_count_after_smooth = co_count * 10 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16363636, 0.14545455, 0.07272727, 0.09090909, 0.4       ,\n",
       "       0.05454545, 0.07272727])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_w = count / count.sum()\n",
    "p_c = p_w\n",
    "p_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00213675, 0.00213675, 0.00213675, 0.00213675, 0.19444444,\n",
       "        0.06623932, 0.02350427],\n",
       "       [0.00213675, 0.00213675, 0.04487179, 0.00213675, 0.17307692,\n",
       "        0.00213675, 0.04487179],\n",
       "       [0.00213675, 0.04487179, 0.00213675, 0.04487179, 0.08760684,\n",
       "        0.00213675, 0.00213675],\n",
       "       [0.00213675, 0.00213675, 0.04487179, 0.00213675, 0.10897436,\n",
       "        0.00213675, 0.02350427],\n",
       "       [0.19444444, 0.17307692, 0.08760684, 0.10897436, 0.00213675,\n",
       "        0.06623932, 0.08760684],\n",
       "       [0.06623932, 0.00213675, 0.00213675, 0.00213675, 0.06623932,\n",
       "        0.00213675, 0.00213675],\n",
       "       [0.02350427, 0.04487179, 0.00213675, 0.02350427, 0.08760684,\n",
       "        0.00213675, 0.00213675]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_wc = co_count_after_smooth / ((co_count_after_smooth.sum() - co_count_after_smooth.trace()) / 2 + co_count_after_smooth.trace())\n",
    "p_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 1.08879055,\n",
       "        2.00434841, 0.68057441],\n",
       "       [0.        , 0.        , 1.44498461, 0.        , 1.09016323,\n",
       "        0.        , 1.44498461],\n",
       "       [0.        , 1.44498461, 0.        , 1.91498824, 1.10243333,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.91498824, 0.        , 1.09754334,\n",
       "        0.        , 1.26836107],\n",
       "       [1.08879055, 1.09016323, 1.10243333, 1.09754334, 0.        ,\n",
       "        1.11053054, 1.10243333],\n",
       "       [2.00434841, 0.        , 0.        , 0.        , 1.11053054,\n",
       "        0.        , 0.        ],\n",
       "       [0.68057441, 1.44498461, 0.        , 1.26836107, 1.10243333,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_w = p_w.reshape(size, 1)\n",
    "p_c = p_c.reshape(1, size)\n",
    "PPMI = np.log(p_wc / (p_w * p_c))\n",
    "PPMI[PPMI < 0] = 0\n",
    "PPMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now instead of using your count matrix, use the PPMI matrix as a weighted count matrix. Then compare the word vector for “dogs” before and after PPMI reweighting. Does PPMI do the right thing to the count matrix? Why? Explain in a few sentences how PPMI helps (short prose will do here; no need to show any math, rather just an intuitive understanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'dogs', 1: 'men', 2: 'feed', 3: 'women', 4: 'the', 5: 'bite', 6: 'like'}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 1.08879055,\n",
       "       2.00434841, 0.68057441])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPMI[word_to_index['dogs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 9., 3., 1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_count[word_to_index['dogs']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the Euclidean distance between the following pairs (you can use the command scipy.linalg.norm to compute the length/norm of a vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dist(word1, word2, matrix):\n",
    "    word1_index = word_to_index[word1]\n",
    "    word2_index = word_to_index[word2]\n",
    "    dist = np.linalg.norm(matrix[word1_index] - matrix[word2_index])\n",
    "    print(\"the distance between {} and {} is {}\".format(word1, word2, dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the distance between women and men is 0.5021491320750741\n",
      "the distance between women and dogs is 2.8337540983685705\n",
      "the distance between dogs and men is 2.5864489017628296\n",
      "the distance between feed and like is 0.9387801747237632\n",
      "the distance between feed and bite is 3.1261219748521154\n",
      "the distance between like and bite is 2.3343443434858924\n"
     ]
    }
   ],
   "source": [
    "calculate_dist('women', 'men', PPMI)\n",
    "calculate_dist('women', 'dogs', PPMI)\n",
    "calculate_dist('dogs', 'men', PPMI)\n",
    "calculate_dist('feed', 'like', PPMI)\n",
    "calculate_dist('feed', 'bite', PPMI)\n",
    "calculate_dist('like', 'bite', PPMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decompose the matrix using singular-value decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.linalg as scipy_linalg\n",
    "U, E, Vt = scipy_linalg.svd(PPMI, full_matrices=False)\n",
    "U = np.matrix(U) # compute U\n",
    "E = np.matrix(np.diag(E)) # compute E\n",
    "Vt = np.matrix(Vt) # compute Vt = conjugage transpose of V \n",
    "V = Vt.T # compute V = conjugate transpose of Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1.30374974, -0.5414387 ,  1.28534614],\n",
       "        [-1.69086253, -1.43533568, -0.497668  ],\n",
       "        [-1.84500612,  1.62973463, -0.76979506],\n",
       "        [-1.81517978, -1.60125958, -0.64873377],\n",
       "        [-2.29424987,  0.06162287,  0.25882216],\n",
       "        [-1.12706364,  0.3266854 ,  1.31523362],\n",
       "        [-1.78245186,  1.41545814, -0.17537147]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_PPMI = PPMI * V[:, 0:3]\n",
    "reduced_PPMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute the Euclidean distances of the human/animal nouns/verbs again but on the reduced PPMI-weighted count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the distance between women and men is 0.2565275547623126\n",
      "the distance between women and dogs is 2.2639448068163546\n",
      "the distance between dogs and men is 2.0317597198696906\n",
      "the distance between feed and like is 0.6349542208353525\n",
      "the distance between feed and bite is 2.561390890605675\n",
      "the distance between like and bite is 1.9587912889282821\n"
     ]
    }
   ],
   "source": [
    "calculate_dist('women', 'men', reduced_PPMI)\n",
    "calculate_dist('women', 'dogs', reduced_PPMI)\n",
    "calculate_dist('dogs', 'men', reduced_PPMI)\n",
    "calculate_dist('feed', 'like', reduced_PPMI)\n",
    "calculate_dist('feed', 'bite', reduced_PPMI)\n",
    "calculate_dist('like', 'bite', reduced_PPMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
